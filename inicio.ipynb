{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1381b72",
   "metadata": {},
   "source": [
    "¬øQu√© Es el Web Scraping?\n",
    "El web scraping es un conjunto de pr√°cticas utilizadas para extraer autom√°ticamente ‚Äî o ¬´scrapear¬ª ‚Äî datos de la web.\n",
    "\n",
    "El web scraping se refiere al proceso de extracci√≥n de contenidos y datos de sitios web mediante software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202bdac",
   "metadata": {},
   "source": [
    "Este script realiza web scraping de la p√°gina de un libro espec√≠fico en el sitio \"Books to Scrape\".\n",
    "\n",
    "Primero, hacemos una petici√≥n HTTP con `requests.get(url)` para obtener el contenido HTML de la p√°gina.\n",
    "\n",
    "Luego, usamos `BeautifulSoup(response.text, 'html.parser')` para convertir ese HTML crudo en un objeto navegable.\n",
    "Esto permite buscar elementos f√°cilmente usando m√©todos como `.find()`, `.select_one()`, etc.\n",
    "\n",
    "Extraemos el t√≠tulo con `soup.find('h1').text`, el precio con `soup.select_one('.price_color').text`,  y lo limpiamos con `.replace()` para quitar caracteres no deseados (como \"√Ç\").\n",
    "\n",
    "Para la disponibilidad, usamos `.select_one('.availability').text.strip()` para eliminar espacios en blanco.\n",
    "\n",
    "La descripci√≥n del libro est√° justo despu√©s del div con id `product_description`, por eso usamos `.find_next_sibling('p')`.\n",
    "\n",
    "Finalmente, las estrellas est√°n codificadas como una clase CSS en la etiqueta <p>, como por ejemplo: `<p class=\"star-rating Three\">.`\n",
    "\n",
    "Al usar `tag['class'][1]`, obtenemos el texto que indica la cantidad de estrellas (por ejemplo, \"Three\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db650b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√≠tulo: A Light in the Attic\n",
      "Precio: ¬£51.77\n",
      "Disponibilidad: In stock (22 available)\n",
      "Descripci√≥n: It's hard to imagine a world without A Light in the Attic. T...\n",
      "Estrellas: Three\n"
     ]
    }
   ],
   "source": [
    "# Extraer la informaci√≥n de un solo libro\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup #Averiguar bien\n",
    "\n",
    "# URL del libro\n",
    "url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "\n",
    "# Hacemos la petici√≥n\n",
    "response = requests.get(url)\n",
    "\n",
    "# BeautifulSoup(response.text, 'html.parser') transforma el HTML crudo en un objeto navegable.\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Obtenemos el t√≠tulo\n",
    "title = soup.find('h1').text\n",
    "\n",
    "# .text te devuelve el texto visible dentro de una etiqueta HTML.\n",
    "# La gente usa .text sin saber qu√© devuelve la etiqueta. Si la etiqueta no tiene texto visible (ej: <img> o <meta>), .text te da vac√≠o.\n",
    "\n",
    "# Obtenemos precio\n",
    "price = soup.select_one('.price_color').text\n",
    "price = price.replace('√Ç', '')  # Limpia cualquier car√°cter raro que aparezca\n",
    "\n",
    "# Obtenemos disponibilidad\n",
    "availability = soup.select_one('.availability').text.strip()\n",
    "\n",
    "# Descripci√≥n (viene en el siguiente <p> despu√©s del div con id 'product_description')\n",
    "desc_tag = soup.find('div', id='product_description')\n",
    "# Usamos `.find_next_sibling('p')`, que busca el **pr√≥ximo hermano (sibling)** que sea una etiqueta <p>.\n",
    "description = desc_tag.find_next_sibling('p').text if desc_tag else \"Sin descripci√≥n\"\n",
    "\n",
    "# Las estrellas est√°n codificadas en la clase CSS de un <p>\n",
    "# Ese guion bajo es una convenci√≥n para evitar conflicto. Internamente, BeautifulSoup ya sabe que class_ se refiere al atributo class del HTML\n",
    "# Al hacer tag['class'], obtenemos una lista como ['star-rating', 'Three'], y el √≠ndice [1] nos da la cantidad de estrellas en texto.\n",
    "star_tag = soup.find('p', class_='star-rating')\n",
    "stars = star_tag['class'][1]\n",
    "\n",
    "# Imprimimos\n",
    "print(f\"T√≠tulo: {title}\")\n",
    "print(f\"Precio: {price}\")\n",
    "print(f\"Disponibilidad: {availability}\")\n",
    "print(f\"Descripci√≥n: {description[:60]}...\")\n",
    "print(f\"Estrellas: {stars}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c25ea1",
   "metadata": {},
   "source": [
    "Scrapeo de varias p√°ginas\n",
    "\n",
    "Que hacen:\n",
    "\n",
    "1. requests.get(url) hace una petici√≥n HTTP a la URL y devuelve la respuesta con el HTML.\n",
    "\n",
    "2. BeautifulSoup transforma el texto HTML en un objeto para buscar etiquetas f√°cilmente.\n",
    "\n",
    "3. .find() busca la primera etiqueta que cumple la condici√≥n.\n",
    "\n",
    "4. .select() busca todas las etiquetas que cumplen un selector CSS (devuelve lista).\n",
    "\n",
    "5. .select_one() busca el primer elemento que cumple el selector CSS (devuelve un tag).\n",
    "\n",
    "6. En las URLs, a veces hay rutas relativas con \"../\", hay que limpiarlas para crear URLs absolutas.\n",
    "\n",
    "7. time.sleep(0.1) hace que el programa espere 0.1 segundos para no saturar el servidor y evitar bloqueos.\n",
    "\n",
    "8. El bucle while True se usa para seguir scrapeando p√°ginas hasta que no haya m√°s p√°ginas siguientes.\n",
    "\n",
    "9. Las estrellas del libro est√°n en la clase CSS 'star-rating X', donde X es la cantidad en texto (One, Two, Three, etc).\n",
    "\n",
    "10. Guardamos los datos en una lista de diccionarios para luego exportarlos o procesarlos f√°cilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3859dd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-last-mile-amos-decker-2_754/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-last-mile-amos-decker-2_754/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d547080>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/a-study-in-scarlet-sherlock-holmes-1_656/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/a-study-in-scarlet-sherlock-holmes-1_656/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d9bbce0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/hide-away-eve-duncan-20_620/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/hide-away-eve-duncan-20_620/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d8b9190>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-widow_609/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-widow_609/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d60af60>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html\n",
      "Total de libros scrapeados: 32\n",
      "[{'Titulo': 'Sharp Objects', 'Precio': '¬£47.82', 'Disponibilidad': 'In stock (20 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/sharp-objects_997/index.html'}, {'Titulo': 'In a Dark, Dark Wood', 'Precio': '¬£19.63', 'Disponibilidad': 'In stock (18 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/in-a-dark-dark-wood_963/index.html'}, {'Titulo': 'The Past Never Ends', 'Precio': '¬£56.50', 'Disponibilidad': 'In stock (16 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/the-past-never-ends_942/index.html'}, {'Titulo': 'A Murder in Time', 'Precio': '¬£16.64', 'Disponibilidad': 'In stock (16 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/a-murder-in-time_877/index.html'}, {'Titulo': 'The Murder of Roger Ackroyd (Hercule Poirot #4)', 'Precio': '¬£44.10', 'Disponibilidad': 'In stock (15 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/the-murder-of-roger-ackroyd-hercule-poirot-4_852/index.html'}, None, {'Titulo': 'That Darkness (Gardiner and Renner #1)', 'Precio': '¬£13.92', 'Disponibilidad': 'In stock (14 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/that-darkness-gardiner-and-renner-1_743/index.html'}, {'Titulo': 'Tastes Like Fear (DI Marnie Rome #3)', 'Precio': '¬£10.69', 'Disponibilidad': 'In stock (14 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/tastes-like-fear-di-marnie-rome-3_742/index.html'}, {'Titulo': 'A Time of Torment (Charlie Parker #14)', 'Precio': '¬£48.35', 'Disponibilidad': 'In stock (14 available)', 'Estrellas': 'Five', 'URL': 'https://books.toscrape.com/catalogue/a-time-of-torment-charlie-parker-14_657/index.html'}, None, {'Titulo': 'Poisonous (Max Revere Novels #3)', 'Precio': '¬£26.80', 'Disponibilidad': 'In stock (12 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/poisonous-max-revere-novels-3_627/index.html'}, {'Titulo': 'Murder at the 42nd Street Library (Raymond Ambler #1)', 'Precio': '¬£54.36', 'Disponibilidad': 'In stock (12 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/murder-at-the-42nd-street-library-raymond-ambler-1_624/index.html'}, {'Titulo': 'Most Wanted', 'Precio': '¬£35.28', 'Disponibilidad': 'In stock (12 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/most-wanted_623/index.html'}, None, {'Titulo': 'Boar Island (Anna Pigeon #19)', 'Precio': '¬£59.48', 'Disponibilidad': 'In stock (12 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/boar-island-anna-pigeon-19_613/index.html'}, None, {'Titulo': 'Playing with Fire', 'Precio': '¬£13.71', 'Disponibilidad': 'In stock (11 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/playing-with-fire_602/index.html'}, {'Titulo': 'What Happened on Beale Street (Secrets of the South Mysteries #2)', 'Precio': '¬£25.37', 'Disponibilidad': 'In stock (7 available)', 'Estrellas': 'Five', 'URL': 'https://books.toscrape.com/catalogue/what-happened-on-beale-street-secrets-of-the-south-mysteries-2_506/index.html'}, {'Titulo': \"The Bachelor Girl's Guide to Murder (Herringford and Watts Mysteries #1)\", 'Precio': '¬£52.30', 'Disponibilidad': 'In stock (7 available)', 'Estrellas': 'Five', 'URL': 'https://books.toscrape.com/catalogue/the-bachelor-girls-guide-to-murder-herringford-and-watts-mysteries-1_491/index.html'}, {'Titulo': 'Delivering the Truth (Quaker Midwife Mystery #1)', 'Precio': '¬£20.89', 'Disponibilidad': 'In stock (7 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/delivering-the-truth-quaker-midwife-mystery-1_464/index.html'}, {'Titulo': 'The Mysterious Affair at Styles (Hercule Poirot #1)', 'Precio': '¬£24.80', 'Disponibilidad': 'In stock (6 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/the-mysterious-affair-at-styles-hercule-poirot-1_452/index.html'}, {'Titulo': 'In the Woods (Dublin Murder Squad #1)', 'Precio': '¬£38.38', 'Disponibilidad': 'In stock (6 available)', 'Estrellas': 'Two', 'URL': 'https://books.toscrape.com/catalogue/in-the-woods-dublin-murder-squad-1_433/index.html'}, {'Titulo': 'The Silkworm (Cormoran Strike #2)', 'Precio': '¬£23.05', 'Disponibilidad': 'In stock (3 available)', 'Estrellas': 'Five', 'URL': 'https://books.toscrape.com/catalogue/the-silkworm-cormoran-strike-2_280/index.html'}, {'Titulo': 'The Exiled', 'Precio': '¬£43.45', 'Disponibilidad': 'In stock (3 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/the-exiled_247/index.html'}, {'Titulo': \"The Cuckoo's Calling (Cormoran Strike #1)\", 'Precio': '¬£19.21', 'Disponibilidad': 'In stock (3 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/the-cuckoos-calling-cormoran-strike-1_239/index.html'}, {'Titulo': 'Extreme Prey (Lucas Davenport #26)', 'Precio': '¬£25.40', 'Disponibilidad': 'In stock (3 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/extreme-prey-lucas-davenport-26_154/index.html'}, {'Titulo': 'Career of Evil (Cormoran Strike #3)', 'Precio': '¬£24.72', 'Disponibilidad': 'In stock (3 available)', 'Estrellas': 'Two', 'URL': 'https://books.toscrape.com/catalogue/career-of-evil-cormoran-strike-3_137/index.html'}, {'Titulo': \"The No. 1 Ladies' Detective Agency (No. 1 Ladies' Detective Agency #1)\", 'Precio': '¬£57.70', 'Disponibilidad': 'In stock (1 available)', 'Estrellas': 'Four', 'URL': 'https://books.toscrape.com/catalogue/the-no-1-ladies-detective-agency-no-1-ladies-detective-agency-1_76/index.html'}, {'Titulo': 'The Girl You Lost', 'Precio': '¬£12.29', 'Disponibilidad': 'In stock (1 available)', 'Estrellas': 'Five', 'URL': 'https://books.toscrape.com/catalogue/the-girl-you-lost_66/index.html'}, {'Titulo': 'The Girl In The Ice (DCI Erika Foster #1)', 'Precio': '¬£15.85', 'Disponibilidad': 'In stock (1 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/the-girl-in-the-ice-dci-erika-foster-1_65/index.html'}, {'Titulo': 'Blood Defense (Samantha Brinkman #1)', 'Precio': '¬£20.30', 'Disponibilidad': 'In stock (1 available)', 'Estrellas': 'Three', 'URL': 'https://books.toscrape.com/catalogue/blood-defense-samantha-brinkman-1_8/index.html'}, {'Titulo': \"1st to Die (Women's Murder Club #1)\", 'Precio': '¬£53.98', 'Disponibilidad': 'In stock (1 available)', 'Estrellas': 'One', 'URL': 'https://books.toscrape.com/catalogue/1st-to-die-womens-murder-club-1_2/index.html'}]\n"
     ]
    }
   ],
   "source": [
    "# Extraer la informaci√≥n de una categor√≠a\n",
    "\n",
    "import requests # Para hacer peticiones HTTPS y obtener el contenido de las p√°ginas\n",
    "from bs4 import BeautifulSoup # Para parsear (analizar) el contenido de la p√°gina web\n",
    "import time # Para pausar entre peticiones y no sobrecargar el servidor\n",
    "\n",
    "base_url = 'https://books.toscrape.com/catalogue/'\n",
    "\n",
    "category_url = 'https://books.toscrape.com/catalogue/category/books/mystery_3/index.html'\n",
    "\n",
    "# Lista donde se guardaran los datos de todos los libros\n",
    "all_books = []\n",
    "\n",
    "# Funci√≥n scrape_book, toma la url de un libro especifico y devuelve los datos scrapeados en forma de diccionario\n",
    "def scrape_book(url):\n",
    "\n",
    "  # Hacemos la petici√≥n\n",
    "  try:\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "  except requests.RequestException as e:\n",
    "    print(f\"‚ùå Error al acceder a {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "  # BeautifulSoup(response.text, 'html.parser') transforma el HTML crudo en un objeto navegable.\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  # Obtenemos el t√≠tulo\n",
    "  title = soup.find('h1').text\n",
    "\n",
    "  # Obtenemos precio\n",
    "  price = soup.select_one('.price_color').text\n",
    "  price = price.replace('√Ç', '')  # Limpia cualquier car√°cter raro que aparezca\n",
    "\n",
    "  # Obtenemos disponibilidad\n",
    "  availability = soup.select_one('.availability').text.strip()\n",
    "\n",
    "  # Descripci√≥n (viene en el siguiente <p> despu√©s del div con id 'product_description')\n",
    "  desc_tag = soup.find('div', id='product_description')\n",
    "  # Usamos `.find_next_sibling('p')`, que busca el **pr√≥ximo hermano (sibling)** que sea una etiqueta <p>.\n",
    "  description = desc_tag.find_next_sibling('p').text if desc_tag else \"Sin descripci√≥n\"\n",
    "\n",
    "  # Las estrellas est√°n codificadas en la clase CSS de un <p>\n",
    "  # Ese guion bajo es una convenci√≥n para evitar conflicto. Internamente, BeautifulSoup ya sabe que class_ se refiere al atributo class del HTML\n",
    "  # Al hacer tag['class'], obtenemos una lista como ['star-rating', 'Three'], y el √≠ndice [1] nos da la cantidad de estrellas en texto.\n",
    "  star_tag = soup.find('p', class_='star-rating')\n",
    "  stars = star_tag['class'][1]\n",
    "\n",
    "  return {\n",
    "    'Titulo': title,\n",
    "    'Precio': price,\n",
    "    'Disponibilidad': availability,\n",
    "    'Estrellas': stars,\n",
    "    'URL': url\n",
    "  }\n",
    "\n",
    "# Funcion scrape_category, toma la url de una categoria, recorre todas sus paginas y scrapea todos los libros que encuentra\n",
    "def scrape_category(url):\n",
    "  while True:\n",
    "    print(f\"Scrapeando pagina: {url}\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Seleccionamos todos los libros en la pagina actual de esa categor√≠a\n",
    "    book_articles = soup.select('article.product_pod')\n",
    "\n",
    "    for book in book_articles:\n",
    "\n",
    "      # Obtenemos el href del libro\n",
    "      relative_url = book.find('h3').find('a')['href']\n",
    "\n",
    "      # relative_url trae la url completa, entonces la limpiamos para despu√©s concatenarla a base_url\n",
    "      book_url = base_url + relative_url.replace('../../../', '')\n",
    "\n",
    "      # Scrapeamos el libro\n",
    "      book_data = scrape_book(book_url)\n",
    "\n",
    "      # Guardamos el resultado\n",
    "      all_books.append(book_data)\n",
    "\n",
    "      # Pausa para evitar sobrecarga\n",
    "      time.sleep(10)\n",
    "\n",
    "    # Verificamos si hay un boton next para seguir scrapeando la sgte pagina\n",
    "    # Usa un selector CSS (li.next > a) para encontrar el link de la siguiente p√°gina. Si existe: next_button va a tener un tag <a>.\n",
    "    next_button = soup.select_one('li.next > a')\n",
    "    if next_button:\n",
    "      next_page_url = next_button['href']\n",
    "      # rsplit(separador, cantidad) divide un string desde el final, y solo hace la cantidad de cortes que vos le indiques.\n",
    "      url = url.rsplit('/', 1)[0] + '/' + next_page_url\n",
    "    else:\n",
    "      break\n",
    "\n",
    "scrape_category(category_url)\n",
    "\n",
    "print(f\"Total de libros scrapeados: {len(all_books)}\")\n",
    "print(all_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad444aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Se encontraron 50 categorias. \n",
      "\n",
      "\n",
      " Scrapeando categoria: Travel -> https://books.toscrape.com/catalogue/category/books/travel_2/index.html\n",
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/travel_2/index.html\n",
      "\n",
      " Scrapeando categoria: Mystery -> https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\n",
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-past-never-ends_942/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-past-never-ends_942/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d5832f0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-murder-of-roger-ackroyd-hercule-poirot-4_852/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-murder-of-roger-ackroyd-hercule-poirot-4_852/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dc20710>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-last-mile-amos-decker-2_754/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-last-mile-amos-decker-2_754/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853eb880b0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/a-study-in-scarlet-sherlock-holmes-1_656/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/a-study-in-scarlet-sherlock-holmes-1_656/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dc202f0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/most-wanted_623/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/most-wanted_623/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dd50b90>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/what-happened-on-beale-street-secrets-of-the-south-mysteries-2_506/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/what-happened-on-beale-street-secrets-of-the-south-mysteries-2_506/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853ebc9910>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-bachelor-girls-guide-to-murder-herringford-and-watts-mysteries-1_491/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-bachelor-girls-guide-to-murder-herringford-and-watts-mysteries-1_491/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dc468a0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/delivering-the-truth-quaker-midwife-mystery-1_464/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/delivering-the-truth-quaker-midwife-mystery-1_464/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dc474a0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/in-the-woods-dublin-murder-squad-1_433/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/in-the-woods-dublin-murder-squad-1_433/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d582ab0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-exiled_247/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-exiled_247/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853e07e9c0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-cuckoos-calling-cormoran-strike-1_239/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-cuckoos-calling-cormoran-strike-1_239/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853dd502c0>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/extreme-prey-lucas-davenport-26_154/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/extreme-prey-lucas-davenport-26_154/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853e07f320>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n",
      "\n",
      " Scrapeando categoria: Historical Fiction -> https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html\n",
      "Scrapeando pagina: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html\n",
      "‚ùå Error al acceder a https://books.toscrape.com/catalogue/the-constant-princess-the-tudor-court-1_493/index.html: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-constant-princess-the-tudor-court-1_493/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d853d92bb30>, 'Connection to books.toscrape.com timed out. (connect timeout=10)'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Scrapeando categoria: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory.text.strip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m     scrape_category(category_url)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mscrape_all_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal de libros scrapeados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_books)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(all_books)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mscrape_all_categories\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    107\u001b[39m category_url = base_site + relative_url\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Scrapeando categoria: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory.text.strip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[43mscrape_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mscrape_category\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     77\u001b[39m   all_books.append(book_data)\n\u001b[32m     79\u001b[39m   \u001b[38;5;66;03m# Pausa para evitar sobrecarga\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m   \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Verificamos si hay un boton next para seguir scrapeando la sgte pagina\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Usa un selector CSS (li.next > a) para encontrar el link de la siguiente p√°gina. Si existe: next_button va a tener un tag <a>.\u001b[39;00m\n\u001b[32m     84\u001b[39m next_button = soup.select_one(\u001b[33m'\u001b[39m\u001b[33mli.next > a\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extraer informaci√≥n de toda la p√°gina\n",
    "\n",
    "import requests # Para hacer peticiones HTTPS y obtener el contenido de las p√°ginas\n",
    "from bs4 import BeautifulSoup # Para parsear (analizar) el contenido de la p√°gina web\n",
    "import time # Para pausar entre peticiones y no sobrecargar el servidor\n",
    "\n",
    "base_url = 'https://books.toscrape.com/catalogue/'\n",
    "\n",
    "# Lista donde se guardaran los datos de todos los libros\n",
    "all_books = []\n",
    "\n",
    "# Funci√≥n scrape_book, toma la url de un libro especifico y devuelve los datos scrapeados en forma de diccionario\n",
    "def scrape_book(url):\n",
    "\n",
    "  # Hacemos la petici√≥n\n",
    "  try:\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "  except requests.RequestException as e:\n",
    "    print(f\"‚ùå Error al acceder a {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "  # BeautifulSoup(response.text, 'html.parser') transforma el HTML crudo en un objeto navegable.\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  # Obtenemos el t√≠tulo\n",
    "  title = soup.find('h1').text\n",
    "\n",
    "  # Obtenemos precio\n",
    "  price = soup.select_one('.price_color').text\n",
    "  price = price.replace('√Ç', '')  # Limpia cualquier car√°cter raro que aparezca\n",
    "\n",
    "  # Obtenemos disponibilidad\n",
    "  availability = soup.select_one('.availability').text.strip()\n",
    "\n",
    "  # Descripci√≥n (viene en el siguiente <p> despu√©s del div con id 'product_description')\n",
    "  desc_tag = soup.find('div', id='product_description')\n",
    "  # Usamos `.find_next_sibling('p')`, que busca el **pr√≥ximo hermano (sibling)** que sea una etiqueta <p>.\n",
    "  description = desc_tag.find_next_sibling('p').text if desc_tag else \"Sin descripci√≥n\"\n",
    "\n",
    "  # Las estrellas est√°n codificadas en la clase CSS de un <p>\n",
    "  # Ese guion bajo es una convenci√≥n para evitar conflicto. Internamente, BeautifulSoup ya sabe que class_ se refiere al atributo class del HTML\n",
    "  # Al hacer tag['class'], obtenemos una lista como ['star-rating', 'Three'], y el √≠ndice [1] nos da la cantidad de estrellas en texto.\n",
    "  star_tag = soup.find('p', class_='star-rating')\n",
    "  stars = star_tag['class'][1]\n",
    "\n",
    "  return {\n",
    "    'Titulo': title,\n",
    "    'Precio': price,\n",
    "    'Disponibilidad': availability,\n",
    "    'Estrellas': stars,\n",
    "    'URL': url\n",
    "  }\n",
    "\n",
    "# Funcion scrape_category, toma la url de una categoria, recorre todas sus paginas y scrapea todos los libros que encuentra\n",
    "def scrape_category(url):\n",
    "  while True:\n",
    "    print(f\"Scrapeando pagina: {url}\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Seleccionamos todos los libros en la pagina actual de esa categor√≠a\n",
    "    book_articles = soup.select('article.product_pod')\n",
    "\n",
    "    for book in book_articles:\n",
    "\n",
    "      # Obtenemos el href del libro\n",
    "      relative_url = book.find('h3').find('a')['href']\n",
    "\n",
    "      # relative_url trae la url completa, entonces la limpiamos para despu√©s concatenarla a base_url\n",
    "      book_url = base_url + relative_url.replace('../../../', '')\n",
    "\n",
    "      # Scrapeamos el libro\n",
    "      book_data = scrape_book(book_url)\n",
    "\n",
    "      # Guardamos el resultado\n",
    "      all_books.append(book_data)\n",
    "\n",
    "      # Pausa para evitar sobrecarga\n",
    "      time.sleep(10)\n",
    "\n",
    "    # Verificamos si hay un boton next para seguir scrapeando la sgte pagina\n",
    "    # Usa un selector CSS (li.next > a) para encontrar el link de la siguiente p√°gina. Si existe: next_button va a tener un tag <a>.\n",
    "    next_button = soup.select_one('li.next > a')\n",
    "    if next_button:\n",
    "      next_page_url = next_button['href']\n",
    "      # rsplit(separador, cantidad) divide un string desde el final, y solo hace la cantidad de cortes que vos le indiques.\n",
    "      url = url.rsplit('/', 1)[0] + '/' + next_page_url\n",
    "    else:\n",
    "      break\n",
    "\n",
    "def scrape_all_categories():\n",
    "\n",
    "  home_url = 'https://books.toscrape.com/index.html'\n",
    "  base_site = 'https://books.toscrape.com/'\n",
    "\n",
    "  response = requests.get(home_url)\n",
    "  response.raise_for_status()\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  category_links = soup.select('div.side_categories ul li ul li a')\n",
    "\n",
    "  print(f\"\\n Se encontraron {len(category_links)} categorias. \\n\")\n",
    "\n",
    "  for category in category_links:\n",
    "    relative_url = category['href']\n",
    "    category_url = base_site + relative_url\n",
    "\n",
    "    print(f\"\\n Scrapeando categoria: {category.text.strip()} -> {category_url}\")\n",
    "\n",
    "    scrape_category(category_url)\n",
    "\n",
    "scrape_all_categories()\n",
    "\n",
    "print(f\"Total de libros scrapeados: {len(all_books)}\")\n",
    "print(all_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842091e",
   "metadata": {},
   "source": [
    "Para poder pasar los datos a un CSV\n",
    "\n",
    "Un archivo CSV (valores separados por comas) es un archivo de texto que tiene un formato espec√≠fico que permite guardar los datos en un formato de tabla estructurada.\n",
    "\n",
    "with ... as f: üëâ Context manager: abre y cierra el archivo solo, incluso si explota algo. f es el manejador.\n",
    "\n",
    "open(path, ...) üëâ ruta del archivo. Si no existe la carpeta, revienta con FileNotFoundError.\n",
    "\n",
    "'w' üëâ write: crea el archivo o sobrescribe si ya existe.\n",
    "\n",
    "newline='' üëâ especial para CSV en Windows: evita que se inserten l√≠neas en blanco entre filas.\n",
    "\n",
    "encoding='utf-8' üëâ guarda acentos/√±/emoji sin romperse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-1.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-2.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-3.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-4.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-5.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-6.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-7.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-8.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-9.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-10.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-11.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-12.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-13.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-14.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-15.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-16.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-17.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-18.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-19.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-20.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-21.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-22.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-23.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-24.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-25.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-26.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-27.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-28.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-29.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-30.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-31.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-32.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-33.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-34.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-35.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-36.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-37.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-38.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-39.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-40.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-41.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-42.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-43.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-44.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-45.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-46.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-47.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-48.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-49.html\n",
      "Scrapeando p√°gina: https://books.toscrape.com/catalogue/page-50.html\n",
      "\n",
      " Total de libros scrapeados: 1000\n",
      "‚úÖ CSV exportado: books.csv (1000 filas)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import csv\n",
    "\n",
    "BASE_URL = \"https://books.toscrape.com/\"\n",
    "CATALOGUE_URL = BASE_URL + \"catalogue/\"\n",
    "\n",
    "all_books = []\n",
    "\n",
    "def fetch_author(title):\n",
    "    try:\n",
    "        url  = f\"https://openlibrary.org/search.json?title={requests.utils.quote(title)}&limit=1\"\n",
    "        resp = requests.get(url, timeout=5)\n",
    "        resp.raise_for_status()\n",
    "        docs = resp.json().get('docs', [])\n",
    "        if docs and docs[0].get('author_name'):\n",
    "            return docs[0]['author_name'][0]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al buscar autor para ¬´{title}¬ª: {e}\")\n",
    "    return \"Desconocido\"\n",
    "\n",
    "def scrape_book(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Error al acceder a {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    title = soup.find('h1').text\n",
    "    author = fetch_author(title)\n",
    "    price = soup.select_one('.price_color').text.replace('√Ç', '')\n",
    "    availability = soup.select_one('.availability').text.strip()\n",
    "\n",
    "    desc_tag = soup.find('div', id='product_description')\n",
    "    description = desc_tag.find_next_sibling('p').text if desc_tag else \"Sin descripci√≥n\"\n",
    "\n",
    "    star_tag = soup.find('p', class_='star-rating')\n",
    "    stars = star_tag['class'][1] if star_tag else \"No rating\"\n",
    "\n",
    "    return {\n",
    "        'Titulo': title,\n",
    "        'Autor': author,\n",
    "        'Precio': price,\n",
    "        'Disponibilidad': availability,\n",
    "        'Estrellas': stars,\n",
    "        'Descripcion': description,\n",
    "        'URL': url\n",
    "    }\n",
    "\n",
    "def scrape_all_books():\n",
    "    url = CATALOGUE_URL + \"page-1.html\"\n",
    "    while True:\n",
    "        print(f\"Scrapeando p√°gina: {url}\")\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        books = soup.select('article.product_pod')\n",
    "        book_urls = []\n",
    "\n",
    "        for b in books:\n",
    "          # Encontramos el href del <a> dentro del <h3>\n",
    "          relative_url = b.find('h3').a['href']\n",
    "\n",
    "          # Limpiamos esa url\n",
    "          cleaned_url = relative_url.replace('../../../', '')\n",
    "\n",
    "          full_url = CATALOGUE_URL + cleaned_url\n",
    "\n",
    "          book_urls.append(full_url)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers = 15) as executor:\n",
    "          results = executor.map(scrape_book, book_urls)\n",
    "          for book_data in  results:\n",
    "            if book_data:\n",
    "              all_books.append(book_data)\n",
    "\n",
    "        # Verificamos si hay un boton next para seguir scrapeando la sgte pagina\n",
    "        # Usa un selector CSS (li.next > a) para encontrar el link de la siguiente p√°gina. Si existe: next_button va a tener un tag <a>.\n",
    "        next_button = soup.select_one('li.next > a')\n",
    "        if next_button:\n",
    "          next_page = next_button['href']\n",
    "          # rsplit(separador, cantidad) divide un string desde el final, y solo hace la cantidad de cortes que vos le indiques.\n",
    "          url = url.rsplit('/', 1)[0] + '/' + next_page\n",
    "        else:\n",
    "          break\n",
    "\n",
    "def export_books_to_csv(rows, path='books.csv'):\n",
    "    \"\"\"\n",
    "    Guarda una lista de dicts (all_books) en un CSV.\n",
    "    - Usa las claves del primer dict como encabezados.\n",
    "    - Codifica en UTF-8.\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        print(\"‚ö†Ô∏è Nada para guardar (lista vac√≠a).\")\n",
    "        return\n",
    "    # escribir encabezados y filas\n",
    "    # Abre el archivo path en modo escritura ('w')\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as f:\n",
    "        headers = list(rows[0].keys())   # columnas: Titulo, Autor, Precio, etc.\n",
    "        w = csv.DictWriter(f, fieldnames=headers) # Crea un escritor CSV que sabe convertir diccionarios en filas, fija el orden de las columnas en el archivo\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)\n",
    "    print(f\"‚úÖ CSV exportado: {path} ({len(rows)} filas)\")\n",
    "\n",
    "\n",
    "scrape_all_books()\n",
    "\n",
    "print(f\"\\n Total de libros scrapeados: {len(all_books)}\")\n",
    "\n",
    "export_books_to_csv(all_books)  # crea books.csv en tu carpeta actual\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba04e7",
   "metadata": {},
   "source": [
    "Como crear una base de datos desde python utilizando SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Conectar la base de datos local 'scraping.db'\n",
    "conector = sqlite3.connect('books.db')\n",
    "cursor = conector.cursor()\n",
    "\n",
    "# Crear tabla autores\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS authors (\n",
    "               id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "               name TEXT UNIQUE\n",
    "               );\n",
    "\"\"\")\n",
    "\n",
    "# Crear tabla de libros\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS books (\n",
    "               id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "               title TEXT,\n",
    "               price REAL,\n",
    "               availability TEXT,\n",
    "               stars INTEGER,\n",
    "               description TEXT,\n",
    "               url TEXT UNIQUE\n",
    "               );\n",
    "\"\"\")\n",
    "\n",
    "# Creamos la tabla intermedia para lograr la relaci√≥n de muchos a muchos\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS books_authors(\n",
    "               book_id INTEGER,\n",
    "               author_id integer,\n",
    "               PRIMARY KEY (book_id, author_id),\n",
    "               FOREIGN KEY (book_id) REFERENCES books(id),\n",
    "               FOREIGN KEY (author_id) REFERENCES authors(id)\n",
    "               )\n",
    "\"\"\")\n",
    "\n",
    "# Confirmamos la creacion de las tablas\n",
    "conector.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05960a6d",
   "metadata": {},
   "source": [
    "Como pasar los datos del CSV a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63fc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, csv, os\n",
    "\n",
    "def import_csv_to_db(csv_path='books.csv', db_path='books.db'):\n",
    "    \"\"\"Carga books.csv a SQLite (crea tablas si faltan).\"\"\"\n",
    "    # Conexi√≥n + FKs\n",
    "    conector = sqlite3.connect(db_path)\n",
    "    conector.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "    cursor = conector.cursor()\n",
    "\n",
    "    # Esquema m√≠nimo (authors, books, books_authors)\n",
    "    cursor.executescript(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS authors (\n",
    "      id   INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "      name TEXT UNIQUE\n",
    "    );\n",
    "    CREATE TABLE IF NOT EXISTS books (\n",
    "      id           INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "      title        TEXT,\n",
    "      price        REAL,\n",
    "      availability TEXT,\n",
    "      stars        INTEGER,\n",
    "      description  TEXT,\n",
    "      url          TEXT UNIQUE\n",
    "    );\n",
    "    CREATE TABLE IF NOT EXISTS books_authors (\n",
    "      book_id   INTEGER NOT NULL,\n",
    "      author_id INTEGER NOT NULL,\n",
    "      PRIMARY KEY (book_id, author_id),\n",
    "      FOREIGN KEY (book_id)   REFERENCES books(id),\n",
    "      FOREIGN KEY (author_id) REFERENCES authors(id)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    star_map = {'One':1,'Two':2,'Three':3,'Four':4,'Five':5}  # texto‚Üín√∫mero\n",
    "    total = 0\n",
    "\n",
    "    # Leer CSV y volcar a DB,  'r' es para read\n",
    "    with open(csv_path, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)  # columnas: Titulo, Autor, Precio, Disponibilidad, Estrellas, Descripcion, URL\n",
    "        for row in reader:\n",
    "            total += 1\n",
    "            title        = (row.get('Titulo') or '').strip()\n",
    "            author_name  = (row.get('Autor') or 'Desconocido').strip()\n",
    "            availability = (row.get('Disponibilidad') or '').strip()\n",
    "            description  = (row.get('Descripcion') or '')\n",
    "            url          = (row.get('URL') or '').strip()\n",
    "\n",
    "            # Precio a float (quita ¬£); si falla, None\n",
    "            raw_price = (row.get('Precio') or '').lstrip('¬£').strip()\n",
    "            try:\n",
    "                price = float(raw_price) if raw_price else None\n",
    "            except ValueError:\n",
    "                price = None\n",
    "\n",
    "            # Estrellas a int (No rating -> 0)\n",
    "            stars = star_map.get((row.get('Estrellas') or '').strip(), 0)\n",
    "\n",
    "            # Autor (evita duplicados)\n",
    "            cursor.execute(\"INSERT OR IGNORE INTO authors(name) VALUES (?)\", (author_name,))\n",
    "            cursor.execute(\"SELECT id FROM authors WHERE name = ?\", (author_name,))\n",
    "            author_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Libro (evita duplicados por URL)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO books(title, price, availability, stars, description, url)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (title, price, availability, stars, description, url))\n",
    "            cursor.execute(\"SELECT id FROM books WHERE url = ?\", (url,))\n",
    "            book_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Relaci√≥n M:N (evita duplicados por PK compuesta)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO books_authors(book_id, author_id)\n",
    "                VALUES (?, ?)\n",
    "            \"\"\", (book_id, author_id))\n",
    "\n",
    "    conector.commit()\n",
    "    cursor.close()\n",
    "    conector.close()\n",
    "    print(f\"‚úÖ Import completado: {total} filas de '{csv_path}' ‚Üí '{os.path.abspath(db_path)}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f82c10",
   "metadata": {},
   "source": [
    "### Consultas emocionales\n",
    "\n",
    "####  C√≥mo leer SQL\n",
    "\n",
    "SELECT ‚Üí qu√© columnas quer√©s ver\n",
    "\n",
    "FROM ‚Üí de qu√© tabla\n",
    "\n",
    "WHERE ‚Üí filtros fila a fila\n",
    "\n",
    "ORDER BY ‚Üí ordenar\n",
    "\n",
    "LIMIT ‚Üí cu√°ntas filas m√°ximo\n",
    "\n",
    "JOIN ‚Üí unir tablas (cuando necesit√°s columnas de m√°s de una)\n",
    "\n",
    "GROUP BY ‚Üí agrupar para contar/promediar\n",
    "\n",
    "HAVING ‚Üí filtrar grupos (despu√©s del GROUP BY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "662367f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Shel Silverstein')\n",
      "(2, 'Sarah Waters')\n",
      "(3, 'Michel Houellebecq')\n",
      "(4, 'Gillian Flynn')\n",
      "(5, 'BookNation')\n",
      "\n",
      "5 filas.\n",
      "('A Light in the Attic', 51.77, 3, 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html')\n",
      "('Tipping the Velvet', 53.74, 1, 'https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html')\n",
      "('Soumission', 50.1, 1, 'https://books.toscrape.com/catalogue/soumission_998/index.html')\n",
      "('Sharp Objects', 47.82, 4, 'https://books.toscrape.com/catalogue/sharp-objects_997/index.html')\n",
      "('Sapiens: A Brief History of Humankind', 54.23, 5, 'https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html')\n",
      "\n",
      "5 filas.\n",
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n",
      "(4, 4)\n",
      "(5, 5)\n",
      "\n",
      "5 filas.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def run_sql(sql, params=()):\n",
    "    conn = sqlite3.connect('books.db')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, params)\n",
    "    rows = cur.fetchall()\n",
    "    for r in rows[:20]:\n",
    "        print(r)\n",
    "    print(f\"\\n{len(rows)} filas.\")\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "run_sql(\"\"\"SELECT * FROM authors LIMIT 5;\"\"\")\n",
    "run_sql(\"\"\"SELECT title, price, stars, url FROM books LIMIT 5;\"\"\")\n",
    "run_sql(\"\"\"SELECT * FROM books_authors LIMIT 5;\"\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90465dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'A Light in the Attic', 51.77, 'In stock (22 available)', 3, \"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\", 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html', 1, 1, 1, 'Shel Silverstein')\n",
      "(2, 'Tipping the Velvet', 53.74, 'In stock (20 available)', 1, '\"Erotic and absorbing...Written with starling power.\"--\"The New York Times Book Review \" Nan King, an oyster girl, is captivated by the music hall phenomenon Kitty Butler, a male impersonator extraordinaire treading the boards in Canterbury. Through a friend at the box office, Nan manages to visit all her shows and finally meet her heroine. Soon after, she becomes Kitty\\'s \"Erotic and absorbing...Written with starling power.\"--\"The New York Times Book Review \" Nan King, an oyster girl, is captivated by the music hall phenomenon Kitty Butler, a male impersonator extraordinaire treading the boards in Canterbury. Through a friend at the box office, Nan manages to visit all her shows and finally meet her heroine. Soon after, she becomes Kitty\\'s dresser and the two head for the bright lights of Leicester Square where they begin a glittering career as music-hall stars in an all-singing and dancing double act. At the same time, behind closed doors, they admit their attraction to each other and their affair begins. ...more', 'https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html', 2, 2, 2, 'Sarah Waters')\n",
      "(3, 'Soumission', 50.1, 'In stock (20 available)', 1, 'Dans une France assez proche de la n√É¬¥tre, un homme s√¢\\x80\\x99engage dans la carri√É¬®re universitaire. Peu motiv√É¬© par l√¢\\x80\\x99enseignement, il s√¢\\x80\\x99attend √É\\xa0 une vie ennuyeuse mais calme, prot√É¬©g√É¬©e des grands drames historiques. Cependant les forces en jeu dans le pays ont fissur√É¬© le syst√É¬®me politique jusqu√¢\\x80\\x99√É\\xa0 provoquer son effondrement. Cette implosion sans soubresauts, sans vraie r√É¬©volution, s Dans une France assez proche de la n√É¬¥tre, un homme s√¢\\x80\\x99engage dans la carri√É¬®re universitaire. Peu motiv√É¬© par l√¢\\x80\\x99enseignement, il s√¢\\x80\\x99attend √É\\xa0 une vie ennuyeuse mais calme, prot√É¬©g√É¬©e des grands drames historiques. Cependant les forces en jeu dans le pays ont fissur√É¬© le syst√É¬®me politique jusqu√¢\\x80\\x99√É\\xa0 provoquer son effondrement. Cette implosion sans soubresauts, sans vraie r√É¬©volution, se d√É¬©veloppe comme un mauvais r√É¬™ve.Le talent de l√¢\\x80\\x99auteur, sa force visionnaire nous entra√É¬Ænent sur un terrain ambigu et glissant ; son regard sur notre civilisation vieillissante fait coexister dans ce roman les intuitions po√É¬©tiques, les effets comiques, une m√É¬©lancolie fataliste.Ce livre est une saisissante fable politique et morale. ...more', 'https://books.toscrape.com/catalogue/soumission_998/index.html', 3, 3, 3, 'Michel Houellebecq')\n",
      "(4, 'Sharp Objects', 47.82, 'In stock (20 available)', 4, 'WICKED above her hipbone, GIRL across her heart Words are like a road map to reporter Camille Preaker√¢\\x80\\x99s troubled past. Fresh from a brief stay at a psych hospital, Camille√¢\\x80\\x99s first assignment from the second-rate daily paper where she works brings her reluctantly back to her hometown to cover the murders of two preteen girls. NASTY on her kneecap, BABYDOLL on her leg Since WICKED above her hipbone, GIRL across her heart Words are like a road map to reporter Camille Preaker√¢\\x80\\x99s troubled past. Fresh from a brief stay at a psych hospital, Camille√¢\\x80\\x99s first assignment from the second-rate daily paper where she works brings her reluctantly back to her hometown to cover the murders of two preteen girls. NASTY on her kneecap, BABYDOLL on her leg Since she left town eight years ago, Camille has hardly spoken to her neurotic, hypochondriac mother or to the half-sister she barely knows: a beautiful thirteen-year-old with an eerie grip on the town. Now, installed again in her family√¢\\x80\\x99s Victorian mansion, Camille is haunted by the childhood tragedy she has spent her whole life trying to cut from her memory. HARMFUL on her wrist, WHORE on her ankle As Camille works to uncover the truth about these violent crimes, she finds herself identifying with the young victims√¢\\x80\\x94a bit too strongly. Clues keep leading to dead ends, forcing Camille to unravel the psychological puzzle of her own past to get at the story. Dogged by her own demons, Camille will have to confront what happened to her years before if she wants to survive this homecoming.With its taut, crafted writing, Sharp Objects is addictive, haunting, and unforgettable. ...more', 'https://books.toscrape.com/catalogue/sharp-objects_997/index.html', 4, 4, 4, 'Gillian Flynn')\n",
      "(5, 'Sapiens: A Brief History of Humankind', 54.23, 'In stock (20 available)', 5, 'From a renowned historian comes a groundbreaking narrative of humanity√¢\\x80\\x99s creation and evolution√¢\\x80\\x94a #1 international bestseller√¢\\x80\\x94that explores the ways in which biology and history have defined us and enhanced our understanding of what it means to be √¢\\x80\\x9chuman.√¢\\x80\\x9dOne hundred thousand years ago, at least six different species of humans inhabited Earth. Yet today there is only one√¢\\x80\\x94h From a renowned historian comes a groundbreaking narrative of humanity√¢\\x80\\x99s creation and evolution√¢\\x80\\x94a #1 international bestseller√¢\\x80\\x94that explores the ways in which biology and history have defined us and enhanced our understanding of what it means to be √¢\\x80\\x9chuman.√¢\\x80\\x9dOne hundred thousand years ago, at least six different species of humans inhabited Earth. Yet today there is only one√¢\\x80\\x94homo sapiens. What happened to the others? And what may happen to us?Most books about the history of humanity pursue either a historical or a biological approach, but Dr. Yuval Noah Harari breaks the mold with this highly original book that begins about 70,000 years ago with the appearance of modern cognition. From examining the role evolving humans have played in the global ecosystem to charting the rise of empires, Sapiens integrates history and science to reconsider accepted narratives, connect past developments with contemporary concerns, and examine specific events within the context of larger ideas.Dr. Harari also compels us to look ahead, because over the last few decades humans have begun to bend laws of natural selection that have governed life for the past four billion years. We are acquiring the ability to design not only the world around us, but also ourselves. Where is this leading us, and what do we want to become?Featuring 27 photographs, 6 maps, and 25 illustrations/diagrams, this provocative and insightful work is sure to spark debate and is essential reading for aficionados of Jared Diamond, James Gleick, Matt Ridley, Robert Wright, and Sharon Moalem. ...more', 'https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html', 5, 5, 5, 'BookNation')\n",
      "(6, 'The Requiem Red', 22.65, 'In stock (19 available)', 1, \"Patient Twenty-nine.A monster roams the halls of Soothing Hills Asylum. Three girls dead. 29 is endowed with the curse√¢\\x80¬¶or gift of perception. She hears messages in music, sees lyrics in paintings. And the corn. A lifetime asylum resident, the orchestral corn music is the only constant in her life.Mason, a new, kind orderly, sees 29 as a woman, not a lunatic. And as his bel Patient Twenty-nine.A monster roams the halls of Soothing Hills Asylum. Three girls dead. 29 is endowed with the curse√¢\\x80¬¶or gift of perception. She hears messages in music, sees lyrics in paintings. And the corn. A lifetime asylum resident, the orchestral corn music is the only constant in her life.Mason, a new, kind orderly, sees 29 as a woman, not a lunatic. And as his belief in her grows, so does her self- confidence. That perhaps she might escape, might see the outside world. But the monster has other plans. The missing girls share one common thread...each was twenty-nine's cell mate. Will she be next? ...more\", 'https://books.toscrape.com/catalogue/the-requiem-red_995/index.html', 6, 6, 6, 'Brynn Chapman')\n",
      "(7, 'The Dirty Little Secrets of Getting Your Dream Job', 33.34, 'In stock (19 available)', 4, \"Drawing on his extensive experience evaluating applicants for his marketing agency, and featuring stories based on real-life situations, sample cover letters, resumes, and straightforward advice, Don Raskin√¢\\x80\\x99s The Dirty Little Secrets of Getting Your Dream Job offers all the necessary tools for navigating the tough job market and securing your dream job.Don Raskin owns and Drawing on his extensive experience evaluating applicants for his marketing agency, and featuring stories based on real-life situations, sample cover letters, resumes, and straightforward advice, Don Raskin√¢\\x80\\x99s The Dirty Little Secrets of Getting Your Dream Job offers all the necessary tools for navigating the tough job market and securing your dream job.Don Raskin owns and operates MME, an advertising and marketing agency in New York City. During his twenty-five years at the agency he has interviewed hundreds of new college graduates for positions within his agency and has placed a strong emphasis on entry-level recruitment for positions in creative, account management, traffic, and production. Raskin has also mentored countless students and their parents on best practices for the job search. Over the years, Raskin has kept exceptionally detailed notes on the interviews he has conducted, observing the good, the bad, the ridiculous, the irreverent. He also has a treasure trove of over-the-top cover letters, resumes, interviews, and post interview follow-ups he has conducted and received. Now, he wants to share all the wisdom and insider secrets he has gathered to help students and first-time job seekers find a job in this economy.Based on his remarkable expertise, Raskin's book provides exclusive insight into the job search process and lets readers in on all of the dirty little secrets to landing their first job√¢\\x80\\x94or a new one√¢\\x80\\x94and finding career success. ...more\", 'https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html', 7, 7, 7, 'Don Raskin')\n",
      "(8, 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 17.93, 'In stock (19 available)', 3, '\"If you have a heart, if you have a soul, Karen Hicks\\' The Coming Woman will make you fall in love with Victoria Woodhull.\"-Kinky Friedman, author and Governor of the Heart of Texas \"What kind of confidence would it take for a woman to buck the old boy\\'s club of politics in 1872? More than 140 years pre-Hillary, there was Victoria Woodhull. This book takes you back with a \"If you have a heart, if you have a soul, Karen Hicks\\' The Coming Woman will make you fall in love with Victoria Woodhull.\"-Kinky Friedman, author and Governor of the Heart of Texas \"What kind of confidence would it take for a woman to buck the old boy\\'s club of politics in 1872? More than 140 years pre-Hillary, there was Victoria Woodhull. This book takes you back with a breathtaking, present-tense bird\\'s eye view into a time when women\\'s liberation was primarily confined to one woman\\'s very capable, independent mind. I couldn\\'t put it down.\"---Ruth Buzzi, Golden Globe Award winner and Television Hall of Fame inductee\"Sadly, too many Americans have never heard of Victoria Woodhull, let alone learned of her story: her revolutionary campaign for the presidency at a time when women weren\\'t even allowed to vote, her support for worker\\'s rights, or her feminist commitment to equality, a century before the official battle over the Equal Rights Amendment. But in The Coming Woman, Karen Hicks brings Woodhull\\'s efforts to life, and reminds us that some of our nation\\'s greatest figures aren\\'t always featured in the history books. It is a riveting account of an amazing woman and her struggle for justice and human dignity, told in an engaging and eminently readable style.\"-Tim Wise, author, \"White Like Me: Reflections on Race from a Privileged Son\"\"The Coming Woman\" is a novel based on the life of feminist Victoria Woodhull, the first woman to run for U.S. President, 50 years before women could even vote!Running for President wasn\\'t Victoria\\'s only first as a woman. She was also the first to own a successful Wall Street firm, the first to publish a successful national newspaper, and the first to head the two-million-member Spiritualist Association. She was the first woman to enter the Senate Judiciary Committee chambers to petition for woman\\'s suffrage, her argument changing the entire focus of the suffragist movement by pointing out that the 14th and 15th Amendments already gave women the vote.In her campaign for the Presidency, Victoria Woodhull boldly addressed many of the issues we still face today: equal pay for equal work; freedom in love; corporate greed and political corruption fueled by powerful lobbyists; and the increasing disparity between the rich and the poor, to name only a few. Her outspoken and common-sense ideas may shed a new perspective on the parallel conundrums of today\\'s world.This bold, beautiful, and sexually progressive woman dared to take on society and religion. To make an example of the hypocrisy in what Mark Twain dubbed The Gilded Age, she exposed the extramarital affairs of the most popular religious figure of the day (Henry Ward Beecher). This led to her persecution and imprisonment and the longest, most infamous trial of the 19th century. But it did not stop her fight for equality.Victoria\\'s epic story, set in the late 1800s, comes to life in a modern, fictional style, while staying true to the actual words and views of the many well-known characters. ...more', 'https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html', 8, 8, 8, 'Desconocido')\n",
      "(9, 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 22.6, 'In stock (19 available)', 4, \"For readers of Laura Hillenbrand's Seabiscuit and Unbroken, the dramatic story of the American rowing team that stunned the world at Hitler's 1936 Berlin Olympics Daniel James Brown√¢\\x80\\x99s robust book tells the story of the University of Washington√¢\\x80\\x99s 1936 eight-oar crew and their epic quest for an Olympic gold medal, a team that transformed the sport and grabbed the attention o For readers of Laura Hillenbrand's Seabiscuit and Unbroken, the dramatic story of the American rowing team that stunned the world at Hitler's 1936 Berlin Olympics Daniel James Brown√¢\\x80\\x99s robust book tells the story of the University of Washington√¢\\x80\\x99s 1936 eight-oar crew and their epic quest for an Olympic gold medal, a team that transformed the sport and grabbed the attention of millions of Americans. The sons of loggers, shipyard workers, and farmers, the boys defeated elite rivals first from eastern and British universities and finally the German crew rowing for Adolf Hitler in the Olympic games in Berlin, 1936. The emotional heart of the story lies with one rower, Joe Rantz, a teenager without family or prospects, who rows not for glory, but to regain his shattered self-regard and to find a place he can call home. The crew is assembled√Ç\\xa0 by an enigmatic coach and mentored by a visionary, eccentric British boat builder, but it is their trust in each other that makes them a victorious team. They remind the country of what can be done when everyone quite literally pulls together√¢\\x80\\x94a perfect melding of commitment, determination, and optimism. Drawing on the boys√¢\\x80\\x99 own diaries and journals, their photos and memories of a once-in-a-lifetime shared dream, The Boys in the Boat is an irresistible story about beating the odds and finding hope in the most desperate of times√¢\\x80\\x94the improbable, intimate story of nine working-class boys from the American west who, in the depths of the Great Depression, showed the world what true grit really meant. It will appeal to readers of Erik Larson, Timothy Egan, James Bradley, and David Halberstam's The Amateurs. ...more\", 'https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html', 9, 9, 9, 'Whizbooks')\n",
      "(10, 'The Black Maria', 52.15, 'In stock (19 available)', 1, 'Praise for Aracelis Girmay:\"[Girmay\\'s] every loss√¢\\x80\\x94she calls them estrangements√¢\\x80\\x94is a yearning for connection across time and place; her every fragment is a bulwark against ruin.\" √¢\\x80\\x94 O, The Oprah Magazine \"In Aracelis Girmay we have a poet who collects, polishes, and shares stories with such brilliant invention, tenderness, and intellectual liveliness that it is understandabl Praise for Aracelis Girmay:\"[Girmay\\'s] every loss√¢\\x80\\x94she calls them estrangements√¢\\x80\\x94is a yearning for connection across time and place; her every fragment is a bulwark against ruin.\" √¢\\x80\\x94 O, The Oprah Magazine \"In Aracelis Girmay we have a poet who collects, polishes, and shares stories with such brilliant invention, tenderness, and intellectual liveliness that it is understandable that we think of her as the blessed curator of our collective histories. There is in her art the vulnerability of one who lives inside of the stories that she gathers in this remarkable collection. Her poems set off alarms even as they transform the world she inhabits, showing us, in the process, exactly what she asks of Romare Bearden√¢\\x80\\x99s art: √¢\\x80\\x98√¢\\x80¬¶how not to // assign all blackness near the sea / a captivity.√¢\\x80\\x99 This is one of the many sweet contradictions in the black maria, which √¢\\x80\\x98is a black flag / wounding the pastoral.√¢\\x80\\x99 I am deeply thankful that we have a poet of her unique and singular talent writing today.\" √¢\\x80\\x94Kwame DawesTaking its name from the moon\\'s dark plains, misidentified as seas by early astronomers, the black maria investigates African diasporic histories, the consequences of racism within American culture, and the question of human identity. Central to this project is a desire to recognize the lives of Eritrean refugees who have been made invisible by years of immigration crisis, refugee status, exile, and resulting statelessness. The recipient of a 2015 Whiting Award for Poetry, Girmay\\'s newest collection elegizes and celebrates life, while wrestling with the humanistic notion of seeing beyond: seeing violence, seeing grace, and seeing each other better.\"to the sea\"great storage house, historyon which we rode, we touchedthe brief pulse of your flutteringpages, spelled with salt & life,your rage, your indifferenceyour gentleness washing our feet,all of you going onwhether or not we live,to you we bring our carnationsyellow & pink, how they floatlike bright sentences atopyour memory\\'s dark hairAracelis Girmay is the author of three poetry collections, the black maria; Kingdom Animalia, which won the Isabella Gardner Award and was a finalist for the NBCC Award; and Teeth. The recipient of a 2015 Whiting Award, she has received grants and fellowships from the Jerome, Cave Canem, and Watson foundations, as well as Civitella Ranieri and the NEA. She currently teaches at Hampshire College\\'s School for Interdisciplinary Arts and in Drew University\\'s low residency MFA program. Originally from Santa Ana, California, she splits her time between New York and Amherst, Massachusetts. ...more', 'https://books.toscrape.com/catalogue/the-black-maria_991/index.html', 10, 10, 10, 'Aracelis Girmay')\n",
      "\n",
      "10 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\" SELECT * FROM books  \n",
    "        JOIN books_authors ON books.id = books_authors.book_id\n",
    "        JOIN authors ON authors.id = books_authors.author_id\n",
    "        LIMIT 10\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90605e14",
   "metadata": {},
   "source": [
    "CAT√ÅSTROFES DE 1 ESTRELLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b214fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Desconocido', 126)\n",
      "('Worth Books', 4)\n",
      "('Harlan Coben', 2)\n",
      "('Sophie Kinsella', 2)\n",
      "('A. C. Grayling', 1)\n",
      "('Ali Benjamin', 1)\n",
      "('Alice Hoffman', 1)\n",
      "('Amanda Jennings', 1)\n",
      "('Andrew Michael Hurley', 1)\n",
      "('Aracelis Girmay', 1)\n",
      "\n",
      "10 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\"SELECT a.name, COUNT(*) AS libros_1_estrella\n",
    "FROM books b\n",
    "JOIN books_authors ba ON ba.book_id = b.id\n",
    "JOIN authors a        ON a.id = ba.author_id\n",
    "WHERE b.stars = 1 \n",
    "GROUP BY a.id\n",
    "ORDER BY libros_1_estrella DESC, a.name\n",
    "LIMIT 10;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e8e8a",
   "metadata": {},
   "source": [
    "BUENO Y BARATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a750653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\"SELECT b.title, a.name AS autor, b.price, b.stars\n",
    "FROM books b\n",
    "JOIN books_authors ba ON ba.book_id = b.id\n",
    "JOIN authors a        ON a.id = ba.author_id\n",
    "WHERE b.stars >= 4 AND b.price < 10\n",
    "ORDER BY b.price ASC\n",
    "LIMIT 25;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432db72",
   "metadata": {},
   "source": [
    "QUIEN TIENE MAS LIBROS EN STOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b719507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Desconocido', 542)\n",
      "('Worth Books', 9)\n",
      "('Stephen King', 7)\n",
      "('David Levithan', 4)\n",
      "('David Sedaris', 4)\n",
      "('Gillian Flynn', 4)\n",
      "('Sophie Kinsella', 4)\n",
      "('Whizbooks', 4)\n",
      "('Jane Austen', 3)\n",
      "('John Green', 3)\n",
      "\n",
      "10 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\"SELECT a.name, COUNT(*) AS en_stock\n",
    "FROM books b\n",
    "JOIN books_authors ba ON ba.book_id = b.id\n",
    "JOIN authors a        ON a.id = ba.author_id\n",
    "WHERE b.availability LIKE 'In stock%'\n",
    "GROUP BY a.id\n",
    "ORDER BY en_stock DESC, a.name\n",
    "LIMIT 10;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2259be",
   "metadata": {},
   "source": [
    "10 LIBROS MAS CAROS CON SUS AUTORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acaa588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"Most Blessed of the Patriarchs\": Thomas Jefferson and the Empire of the Imagination', 'Desconocido')\n",
      "('#HigherSelfie: Wake Up Your Life. Free Your Soul. Find Your Tribe.', 'Desconocido')\n",
      "('(Un)Qualified: How God Uses Broken People to Do Big Things', 'Desconocido')\n",
      "('1,000 Places to See Before You Die', 'Patricia Schultz')\n",
      "('10-Day Green Smoothie Cleanse: Lose Up to 15 Pounds in 10 Days!', 'Desconocido')\n",
      "('A Flight of Arrows (The Pathfinders #2)', 'Desconocido')\n",
      "(\"A Gentleman's Position (Society of Gentlemen #3)\", 'Desconocido')\n",
      "('A Heartbreaking Work of Staggering Genius', 'Dave Eggers')\n",
      "(\"A New Earth: Awakening to Your Life's Purpose\", 'Desconocido')\n",
      "('A Piece of Sky, a Grain of Rice: A Memoir in Four Meditations', 'Desconocido')\n",
      "\n",
      "10 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\"SELECT b.title, a.name\n",
    "FROM books b\n",
    "JOIN books_authors ba ON ba.book_id = b.id\n",
    "JOIN authors a        ON a.id = ba.author_id\n",
    "WHERE b.stars = 5\n",
    "ORDER BY b.title\n",
    "LIMIT 10;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78025a",
   "metadata": {},
   "source": [
    "PRECIO PROMEDIO GENERAL DE LIBROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8de62d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35.07,)\n",
      "\n",
      "1 filas.\n"
     ]
    }
   ],
   "source": [
    "run_sql(\"\"\"SELECT ROUND(AVG(price), 2) FROM books;\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
